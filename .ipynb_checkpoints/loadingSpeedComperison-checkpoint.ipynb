{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f914d2c-525a-444f-a627-1d947907cd75",
   "metadata": {},
   "source": [
    "In this notebook, we test the loading speed for raster satellite data <br> stored in different data formats and\n",
    "for different preprocessing steps for the purpose of using\n",
    "it in a deep-learning dataset.\n",
    "\n",
    "Any questions? Contact jonathanprexl@gmail.com\n",
    "\n",
    "\n",
    "For running the code in this notebook please download the Sentinel-2 image:<br> \n",
    "**S2B_MSIL2A_20230928T101719_N0509_R065_T32UPU_20230928T145710.SAFE**<br> \n",
    "from https://dataspace.copernicus.eu/ and store it in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a437e4-690a-47d8-8886-5575a7e11f01",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e87c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.enums import Compression\n",
    "\n",
    "import time\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adad85c4-333c-4fbb-a398-faefdfc36536",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"./S2B_MSIL2A_20230928T101719_N0509_R065_T32UPU_20230928T145710.SAFE\"):\n",
    "    raise FileNotFoundError(\"you need to download and extract the S2 file first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3a8c5-c5c2-4e1d-a806-83a8b82298e6",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46e81fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numSamples = 1024 # statistics over N samples\n",
    "patchsize = 256 # patchsize to load\n",
    "\n",
    "tempdir = \"./tmp\" # location for temporary files\n",
    "os.makedirs(tempdir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331b3294-164e-45c6-97bc-c659b302ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "globaltimes = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5b850",
   "metadata": {},
   "source": [
    "# Loading from the default .jp2 files\n",
    "\n",
    "Often Sentinel-2 data gets shipped in the .SAFE format where all bands are stored in separate files in the .jp2 format.\n",
    "The file covers approximately an area of 100km² x 100km². We can load random patches via the windowed loading function of rasterio. \n",
    "If we use this format as is then upsampling of the non 10m GSD bands takes place during loading (ofc a bit slower).\n",
    "This is the default method (our baseline) without any preprocessing or change of data format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a948363-251a-4505-b904-6747e202def1",
   "metadata": {},
   "source": [
    "Get the location of all the seperate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b490009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_S2_locations(s2_dir):\n",
    "    \n",
    "    s2_b01 = glob.glob(os.path.join(s2_dir,\"**\",\"*B01_60m.jp2\"),recursive=True)\n",
    "    s2_b02 = glob.glob(os.path.join(s2_dir,\"**\",\"*B02_10m.jp2\"),recursive=True)\n",
    "    s2_b03 = glob.glob(os.path.join(s2_dir,\"**\",\"*B03_10m.jp2\"),recursive=True)\n",
    "    s2_b04 = glob.glob(os.path.join(s2_dir,\"**\",\"*B04_10m.jp2\"),recursive=True)\n",
    "    s2_b05 = glob.glob(os.path.join(s2_dir,\"**\",\"*B05_20m.jp2\"),recursive=True)\n",
    "    s2_b06 = glob.glob(os.path.join(s2_dir,\"**\",\"*B06_20m.jp2\"),recursive=True)\n",
    "    s2_b07 = glob.glob(os.path.join(s2_dir,\"**\",\"*B07_20m.jp2\"),recursive=True)\n",
    "    s2_b08 = glob.glob(os.path.join(s2_dir,\"**\",\"*B08_10m.jp2\"),recursive=True)\n",
    "    s2_b8a = glob.glob(os.path.join(s2_dir,\"**\",\"*B8A_20m.jp2\"),recursive=True)\n",
    "    s2_b09 = glob.glob(os.path.join(s2_dir,\"**\",\"*B09_60m.jp2\"),recursive=True)\n",
    "    s2_b11 = glob.glob(os.path.join(s2_dir,\"**\",\"*B11_20m.jp2\"),recursive=True)\n",
    "    s2_b12 = glob.glob(os.path.join(s2_dir,\"**\",\"*B12_20m.jp2\"),recursive=True)\n",
    "\n",
    "    s2_b01 = s2_b01[0]\n",
    "    s2_b02 = s2_b02[0]\n",
    "    s2_b03 = s2_b03[0]\n",
    "    s2_b04 = s2_b04[0]\n",
    "    s2_b05 = s2_b05[0]\n",
    "    s2_b06 = s2_b06[0]\n",
    "    s2_b07 = s2_b07[0]\n",
    "    s2_b08 = s2_b08[0]\n",
    "    s2_b8a = s2_b8a[0]\n",
    "    s2_b09 = s2_b09[0]\n",
    "    s2_b11 = s2_b11[0]\n",
    "    s2_b12 = s2_b12[0]\n",
    "    \n",
    "    return {\"b01\":s2_b01,\"b02\":s2_b02,\"b03\":s2_b03,\"b04\":s2_b04,\"b05\":s2_b05,\n",
    "            \"b06\":s2_b06,\"b07\":s2_b07,\"b08\":s2_b08,\"b8a\":s2_b8a,\"b09\":s2_b09,\n",
    "            \"b11\":s2_b11,\"b12\":s2_b12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a79a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_raw = get_S2_locations(\"./S2B_MSIL2A_20230928T101719_N0509_R065_T32UPU_20230928T145710.SAFE/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d96e44-1080-4752-b7bd-71314c1271db",
   "metadata": {},
   "source": [
    "### Load random patches\n",
    "\n",
    "loading of N random patches from the 100km² x 100km² file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "956c3d31",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_520138/3867768253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_left\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_bottom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_left\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpatchsize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_bottom\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpatchsize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# no upsampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/rasterio/windows.py\u001b[0m in \u001b[0;36mfrom_bounds\u001b[0;34m(left, bottom, right, top, transform, height, width, precision)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     rows, cols = rowcol(\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/rasterio/transform.py\u001b[0m in \u001b[0;36mrowcol\u001b[0;34m(transform, xs, ys, op, precision)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__iter__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__iter__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             fcols, frows = zip(\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvtransform\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/rasterio/transform.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__iter__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__iter__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             fcols, frows = zip(\n\u001b[0;32m--> 229\u001b[0;31m                 \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvtransform\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             )\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/affine/__init__.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0m__iadd__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \"\"\"Multiplication\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "times = [] # store loading times\n",
    "\n",
    "# get the bounds of the raster\n",
    "with rio.open(locs_raw[\"b02\"],\"r\") as src:\n",
    "    bounds = src.bounds\n",
    "    transform = src.transform\n",
    "\n",
    "# load N random windows\n",
    "for i in range(numSamples):\n",
    "    \n",
    "    x0,y0 = np.random.randint(0,10980-patchsize,2)\n",
    "    new_left = bounds.left + x0*10\n",
    "    new_bottom = bounds.bottom + y0*10  \n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    tensor = []\n",
    "    for band in locs_raw.keys():\n",
    "        with rio.open(locs_raw[band],\"r\") as src:\n",
    "            \n",
    "            win = from_bounds(new_left,new_bottom,new_left+patchsize*10,new_bottom+patchsize*10,src.transform)\n",
    "\n",
    "            # no upsampling\n",
    "            if band in [\"b02\",\"b03\",\"b04\",\"b08\"]:\n",
    "                tensor.append( src.read(1, window=win) )\n",
    "\n",
    "            # upsampling\n",
    "            else:\n",
    "                tensor.append( src.read(1, window=win, out_shape=(1,patchsize,patchsize), resampling=Resampling.cubic) )\n",
    "    \n",
    "    tensor = np.stack(tensor,axis=0)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    times.append(t1-t0)\n",
    "\n",
    "globaltimes[\"jp2\"] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(times)),times)\n",
    "plt.title(\"mean loading time: \"+str(np.mean(times)))\n",
    "plt.ylabel(\"loading time\")\n",
    "plt.xlabel(\"itteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74858025",
   "metadata": {},
   "source": [
    "# Make a geotiff with all data combined and load windows from there\n",
    "\n",
    "Faster then loading from separate files is if we place all bands into one geotiff beforehand (only have to be done once). Here we can set the tiling variable in the file metadata which influences the i/o speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d21811",
   "metadata": {},
   "source": [
    "### Save all bands into one geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGeotiff(tilling, blocksize=256, overwriteName=\"\", compress=False):\n",
    "\n",
    "    tensor = []\n",
    "    for band in locs_raw.keys():\n",
    "        with rio.open(locs_raw[band],\"r\") as src:\n",
    "            if band in [\"b02\",\"b03\",\"b04\",\"b08\"]:\n",
    "                tensor.append( src.read(1) )\n",
    "            else:\n",
    "                tensor.append( src.read(1, out_shape=(1,10980,10980),resampling=Resampling.cubic) )\n",
    "    tensor = np.stack(tensor,axis=0)\n",
    "\n",
    "    with rio.open(locs_raw[\"b02\"],\"r\") as src:\n",
    "        meta = src.meta\n",
    "        \n",
    "    meta[\"driver\"]=\"GTiff\"\n",
    "    meta[\"count\"]=12\n",
    "    meta[\"dtype\"]= rio.uint16\n",
    "\n",
    "    if compress:\n",
    "        meta[\"compress\"] = Compression.lzw.name\n",
    "    else:\n",
    "        meta[\"compress\"] = Compression.none.name\n",
    "    \n",
    "    if tilling:\n",
    "        meta[\"tiled\"] = True\n",
    "        meta[\"blocksize\"] = blocksize\n",
    "    else:\n",
    "        meta[\"tiled\"] = False\n",
    "\n",
    "    if overwriteName == \"\":\n",
    "        with rio.open(os.path.join(tempdir, f\"S2cube_tiled_{str(tilling)}.tif\"),\"w\",**meta) as dst:\n",
    "            dst.write(tensor)\n",
    "    else:\n",
    "        with rio.open(overwriteName,\"w\",**meta) as dst:\n",
    "            dst.write(tensor)\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36464b4-6276-4db4-8251-ce9aa205eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "toGeotiff(tilling=False)\n",
    "toGeotiff(tilling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03187287-74c9-42ed-b804-f378b6e6723d",
   "metadata": {},
   "source": [
    "### load from the cube without tilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "# get the bounds of the raster\n",
    "with rio.open(os.path.join(tempdir,\"S2cube_tiled_False.tif\"),\"r\") as src:\n",
    "    bounds = src.bounds\n",
    "    transform = src.transform\n",
    "\n",
    "# load N random windows\n",
    "for i in range(numSamples):\n",
    "    \n",
    "    x0,y0 = np.random.randint(0,10980-patchsize,2)\n",
    "    new_left = bounds.left + x0*10\n",
    "    new_bottom = bounds.bottom + y0*10  \n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    with rio.open(os.path.join(tempdir,\"S2cube_tiled_False.tif\"),\"r\") as src:\n",
    "\n",
    "        win = from_bounds(new_left,new_bottom,new_left+patchsize*10,new_bottom+patchsize*10,src.transform)\n",
    "\n",
    "        tensor = src.read(window=win)\n",
    "\n",
    "    t1 = time.time()\n",
    "    \n",
    "    times.append(t1-t0)\n",
    "\n",
    "globaltimes[\"gtif_nT\"] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742dd61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(times)),times)\n",
    "plt.title(\"mean loading time: \"+str(np.mean(times)))\n",
    "plt.ylabel(\"loading time\")\n",
    "plt.xlabel(\"itteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eaf1ac",
   "metadata": {},
   "source": [
    "### load from the cube with tilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0474ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "# get the bounds of the raster\n",
    "with rio.open(os.path.join(tempdir,\"S2cube_tiled_True.tif\"),\"r\") as src:\n",
    "    bounds = src.bounds\n",
    "    transform = src.transform\n",
    "\n",
    "# load N random windows\n",
    "for i in range(numSamples):\n",
    "    \n",
    "    x0,y0 = np.random.randint(0,10980-patchsize,2)\n",
    "    new_left = bounds.left + x0*10\n",
    "    new_bottom = bounds.bottom + y0*10  \n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    with rio.open(os.path.join(tempdir,\"S2cube_tiled_True.tif\"),\"r\") as src:\n",
    "\n",
    "        win = from_bounds(new_left,new_bottom,new_left+patchsize*10,new_bottom+patchsize*10,src.transform)\n",
    "\n",
    "        tensor = src.read(window=win)\n",
    "\n",
    "    t1 = time.time()\n",
    "    \n",
    "    times.append(t1-t0)\n",
    "\n",
    "globaltimes[\"gtif_T\"] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(times)),times)\n",
    "plt.title(\"mean loading time: \"+str(np.mean(times)))\n",
    "plt.ylabel(\"loading time\")\n",
    "plt.xlabel(\"itteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d5419-34e3-45e9-a7d0-ef5b99fa6914",
   "metadata": {},
   "source": [
    "# load from compressed tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85576f94-01f6-4f6d-ba31-e0234bec9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "toGeotiff(tilling=True,overwriteName=os.path.join(tempdir,\"S2cube_withCompression.tif\"),compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5666551-b1f7-4ad0-838a-8d2ac521831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "# get the bounds of the raster\n",
    "with rio.open(os.path.join(tempdir,\"S2cube_withCompression.tif\"),\"r\") as src:\n",
    "    bounds = src.bounds\n",
    "    transform = src.transform\n",
    "\n",
    "# load N random windows\n",
    "for i in range(numSamples):\n",
    "    \n",
    "    x0,y0 = np.random.randint(0,10980-patchsize,2)\n",
    "    new_left = bounds.left + x0*10\n",
    "    new_bottom = bounds.bottom + y0*10  \n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    with rio.open(os.path.join(tempdir,\"S2cube_withCompression.tif\"),\"r\") as src:\n",
    "\n",
    "        win = from_bounds(new_left,new_bottom,new_left+patchsize*10,new_bottom+patchsize*10,src.transform)\n",
    "\n",
    "        tensor = src.read(window=win)\n",
    "\n",
    "    t1 = time.time()\n",
    "    \n",
    "    times.append(t1-t0)\n",
    "\n",
    "globaltimes[\"gtif_T_compressed\"] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30180602-b1a6-4a8b-abfe-2d64c075928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(times)),times)\n",
    "plt.title(\"mean loading time: \"+str(np.mean(times)))\n",
    "plt.ylabel(\"loading time\")\n",
    "plt.xlabel(\"itteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebfbdc",
   "metadata": {},
   "source": [
    "### Try differnt blocksizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c557c91-7d8b-417f-bbe8-e37179eb9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for BS in [128,256,512,1024,2048,4096]:\n",
    "#    \n",
    "#    toGeotiff(tilling=True, blocksize=BS, overwriteName=os.path.join(tempdir,\"itterateBlocksize.tif\"))\n",
    "#\n",
    "#    times = []\n",
    "#    \n",
    "#    # get the bounds of the raster\n",
    "#    with rio.open(os.path.join(tempdir,\"itterateBlocksize.tif\"),\"r\") as src:\n",
    "#        bounds = src.bounds\n",
    "#        transform = src.transform\n",
    "#    \n",
    "#    # load N random windows\n",
    "#    for i in range(numSamples):\n",
    "#        \n",
    "#        x0,y0 = np.random.randint(0,10980-patchsize,2)\n",
    "#        new_left = bounds.left + x0*10\n",
    "#        new_bottom = bounds.bottom + y0*10  \n",
    "#        \n",
    "#        t0 = time.time()\n",
    "#    \n",
    "#        with rio.open(os.path.join(tempdir,\"itterateBlocksize.tif\"),\"r\") as src:\n",
    "#    \n",
    "#            win = from_bounds(new_left,new_bottom,new_left+patchsize*10,new_bottom+patchsize*10,src.transform)\n",
    "#    \n",
    "#            tensor = src.read(window=win)\n",
    "#    \n",
    "#        t1 = time.time()\n",
    "#        \n",
    "#        times.append(t1-t0)\n",
    "#\n",
    "#    globaltimes[f\"gtif_T_iBS_{BS}\"] = times\n",
    "#\n",
    "#    plt.scatter(range(len(times)),times)\n",
    "#    plt.title(\"mean loading time: \"+str(np.mean(times))+f\" -- Blocksize {BS}\")\n",
    "#    plt.ylabel(\"loading time\")\n",
    "#    plt.xlabel(\"itteration\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b1a9d",
   "metadata": {},
   "source": [
    "# Loading patches from hdf5 file\n",
    "\n",
    "Alternativly to reading with windows from a \"big\" rasterfile we can also prepocess the data beforhand and store the \n",
    "seperate patches in a hdf4 file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b467c6",
   "metadata": {},
   "source": [
    "### generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the bounds of the raster\n",
    "with rio.open(os.path.join(tempdir,\"S2cube_tiled_True.tif\"),\"r\") as src:\n",
    "    bounds = src.bounds\n",
    "    transform = src.transform\n",
    "\n",
    "# write random patches into a hdf5 file\n",
    "locs = []\n",
    "with h5py.File(os.path.join(tempdir,'S2patches.h5'), 'w') as hdf:\n",
    "    # load N random windows\n",
    "    for i in range(1764): # 1764 is roughtly 42**2 which is the number of 256**2 patches in the 10980x10980 raster\n",
    "        x0,y0 = np.random.randint(0,10980-patchsize,2)\n",
    "        new_left = bounds.left + x0*10\n",
    "        new_bottom = bounds.bottom + y0*10  \n",
    "        with rio.open(os.path.join(tempdir,\"S2cube_tiled_True.tif\"),\"r\") as src:\n",
    "            win = from_bounds(new_left,new_bottom,new_left+patchsize*10,new_bottom+patchsize*10,src.transform)\n",
    "            tensor = src.read(window=win)\n",
    "            hdf.create_dataset(f'dataset_{i}', data=tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa6591c",
   "metadata": {},
   "source": [
    "### perform read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "# load N random windows\n",
    "for i in range(numSamples):\n",
    "\n",
    "    j = np.random.randint(0,1764)\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    with h5py.File(os.path.join(tempdir,'S2patches.h5'), 'r') as hdf:\n",
    "        data = hdf[f'dataset_{j}'][:]\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    times.append(t1-t0)\n",
    "\n",
    "globaltimes[f\"hdf5\"] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ecd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(times)),times)\n",
    "plt.title(\"mean loading time: \"+str(np.mean(times))+f\" -- Blocksize {BS}\")\n",
    "plt.ylabel(\"loading time\")\n",
    "plt.xlabel(\"itteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d848a-d3a2-4708-bcd6-687c2d266a43",
   "metadata": {},
   "source": [
    "# Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccded4-0ded-4f8f-be95-a9f8821ed423",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=dict()\n",
    "for key, val in globaltimes.items():\n",
    "    if not \"iBS\" in key:\n",
    "        mean = np.mean(val)\n",
    "        std = np.std(val)\n",
    "        stats[key] = {'mean': mean, 'std': std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e7078-f347-48d2-91ab-e294fb273c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(stats.keys())\n",
    "means = [stats[key]['mean'] for key in keys]\n",
    "stds = [stats[key]['std'] for key in keys]\n",
    "\n",
    "\n",
    "xlabels={\n",
    "    \"jp2\": \"jp2\",\n",
    "    \"gtif_nT\": \"GTiff without tilling\",\n",
    "    \"jp2\": \"GTiff with tilling\",\n",
    "    \"hdf5\": \"hdf5\",\n",
    "}\n",
    "\n",
    "\n",
    "plt.errorbar(keys, means, yerr=stds, fmt='o', capsize=5, label='Mean ± STD')\n",
    "plt.xlabel('dataformat')\n",
    "plt.ylabel('loadingtime (s)')\n",
    "plt.title('mean and sdt of the loading speed for dataformat')\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359581a-dd4d-4850-8f13-3ed71ec0c380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
